{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a085ebae-911c-4d49-830a-9882b18e3146",
   "metadata": {},
   "source": [
    "Q1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca545d34-477d-489c-941f-462bb5b1da7c",
   "metadata": {},
   "source": [
    "Web scraping is an automatic method to obtain large amounts of data from websites. Most of this data is unstructured data in an HTML format which is then converted into structured data in a spreadsheet or a database so that it can be used in various applications. There are many different ways to perform web scraping to obtain data from websites. These include\n",
    "\n",
    "1. using online services,\n",
    "2. particular API’s\n",
    "3. or by creating our code for web scraping from scratch.\n",
    "\n",
    "Web Scraping has multiple uses:\n",
    "\n",
    "1. Price Monitoring\n",
    "\n",
    "Web Scraping can be used by companies to scrap the product data for their products and competing products as well to see how it impacts their pricing strategies. Companies can use this data to fix the optimal pricing for their products so that they can obtain maximum revenue.\n",
    "\n",
    "2. Market Research\n",
    "\n",
    "Web scraping can be used for market research by companies. High-quality web scraped data obtained in large volumes can be very helpful for companies in analyzing consumer trends and understanding which direction the company should move in the future.\n",
    "\n",
    "3. Email Marketing\n",
    "\n",
    "Companies can also use Web scraping for email marketing. They can collect Email ID’s from various sites using web scraping and then send bulk promotional and marketing Emails to all the people owning these Email ID’s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c824863-1db3-48fe-8a0c-c3381af283c7",
   "metadata": {},
   "source": [
    "Q2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445ef31b-855f-4ec8-b94d-9dc5594b60e4",
   "metadata": {},
   "source": [
    "1. COPY-PASTING:\n",
    "\n",
    "This is a manual way for scraping here we do is copy and paste web content. This is time-consuming and repetitive and begs for a more effective means of web scraping.\n",
    "\n",
    "2. HTML PARSING:\n",
    "\n",
    "HTML parsing is done with JavaScript and targets linear or nested HTML pages. It is a fast and robust method that is used for text extraction, screen scraping, and resource extraction among others.\n",
    "\n",
    "3. DOM PARSING :\n",
    "\n",
    "DOM is Document Object Model and it defines the style structure and content of XML files. Scrapers make use of DOM parsers to get an in-depth view of a web page’s structure.\n",
    "\n",
    "4. GOOGLE SHEETS:\n",
    "\n",
    "Google sheets are a web scraping tool that is quite popular among web scrapers. From within sheets, a scraper can make use of IMPORT XML () function to scrape as much data as is needed from websites."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5066183f-3fbc-4d1c-8d2d-bd576e9bac00",
   "metadata": {},
   "source": [
    "Q3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629df4f5-ee37-4e45-90cc-961c55737720",
   "metadata": {},
   "source": [
    "Beautifulsoup is a python package used for parsing HTML and XML documents it creates a parse tree for parsed pages which can be used for web scraping. It pulls data from HTML and XML files and works with our parser to provide the idiomatic way of navigating, searching and modifying the parse tree."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48d74ed-2628-4810-9236-b38f36fd5acd",
   "metadata": {},
   "source": [
    "Q4."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3448beaf-0955-416c-8b46-eeef1b5ab76b",
   "metadata": {},
   "source": [
    "Because flask is web framework which provides with tools, libraries, and technology that allow you to build a web application.\n",
    "\n",
    "Also flask is a micro-framework. Micro-framework are frameworks which are little dependecies to external libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa0dc55-2b97-4645-848c-59ee7775b370",
   "metadata": {},
   "source": [
    "Q5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc583a9-c001-4fc0-a62f-ef4cc281733b",
   "metadata": {},
   "source": [
    "Codepipeline and Elastic Beanstalk used in this project.\n",
    "\n",
    "1. AWS Codepipeline is a continuous delivery service you can use to model, visualize, and automate the steps required to   release your software. You can quickly model and configure the different stages of a software release process. Codepipeline automates the steps required to release your software changes continuously.\n",
    "\n",
    "2. Elastic Beanstalk is a service for deploying and scaling web applications and services. Here we have to upload our code and Elastic Beanstalk automatically handles the deployment—from capacity provisioning, load balancing, and auto scaling to application health monitoring.\n",
    "\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
